{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of training meta learner with example predictions\n",
    "Written by Congcong Yuan, 2023-02\n",
    "\n",
    "Outline of this tutorial:\n",
    "\n",
    "0. Install packages\n",
    "1. Import packages and functions\n",
    "2. Load data and prepare training data\n",
    "3. Train meta learner\n",
    "4. Save your model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the required packages by pip3 on virtual machine\n",
    "!pip3 install seisbench\n",
    "!pip3 install ELEP==0.0.2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from ELEP.elep.ensemble_learners import ensemble_regressor_cnn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. load data and prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metadata which includes labels\n",
    "!wget https://github.com/congcy/ELEP/raw/main/docs/tutorials/data/events_metadata.csv\n",
    "!wget https://drive.google.com/file/d/15U0KWTYa3l7lNrFVAqKAf7XrLHcAqa_q/view -O pretrain_prediction.npy\n",
    "# dirpath_data = '/mnt/Data02/DataDL/Ensemble/INSTANCE_prediction_02/original/training/'\n",
    "# dirpath_data2 = '/mnt/Data02/DataDL/Ensemble/INSTANCE_prediction_02/original/training/CNN_regress/'\n",
    "# npy_fnm = 'Instance_training_set_original.npy'\n",
    "# csv_fnm = 'Instance_training_set_original.csv'\n",
    "# model_fnm = 'Instance_training_set_original_tp_L2k.pt'\n",
    "# valid_fnm = 'Instance_validation_set_original_tp_L2k'\n",
    "# pdata = np.load(dirpath_data + npy_fnm)\n",
    "# # load csv\n",
    "# csv_reader = pd.read_csv(dirpath_data+csv_fnm)\n",
    "# trace_name_list = csv_reader['trace_name'].values\n",
    "# trace_stt_list = csv_reader['trace_start_time'].values\n",
    "# tp_sample_list = csv_reader['p_arrival_sample'].values\n",
    "# ts_sample_list = csv_reader['s_arrival_sample'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds = np.load('./data/events_pretrain_predictions.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data and labels\n",
    "[nsamples, nphases, nmdls, npts] = pdata.shape\n",
    "ntwin = 2000\n",
    "cdata = np.zeros([nsamples, 1, nmdls, ntwin]) # Put P&S together, [N,C,H,W]\n",
    "clabels = np.zeros([nsamples, 1]) # labels\n",
    "it_labels = np.zeros([nsamples, ], dtype=int)\n",
    "for isamp in range(nsamples):\n",
    "    # extract manual/labled picks\n",
    "    itp, its = tp_sample_list[isamp], ts_sample_list[isamp]\n",
    "    # cut and write data\n",
    "    itind = random.randint(100, 1900)\n",
    "    if itp-itind+ntwin >= npts:\n",
    "        itind = itp+ntwin-npts\n",
    "    if itp-itind < 0:\n",
    "        itind = itp\n",
    "    cdata[isamp] = pdata[isamp,0:1,:,itp-itind:itp-itind+ntwin]\n",
    "\n",
    "    it_labels[isamp] = itind\n",
    "    # make label between 0 and 1\n",
    "    clabels[isamp] = itind/ntwin\n",
    "\n",
    "# remove variable\n",
    "del pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to training and validation datasets\n",
    "split_rate = 1.0\n",
    "nsplit = int(split_rate*nsamples)\n",
    "cdata_train = torch.Tensor(cdata[:nsplit])\n",
    "cdata_test = torch.Tensor(cdata[nsplit:])\n",
    "\n",
    "clabels_train = torch.Tensor(clabels[:nsplit])\n",
    "clabels_test = torch.Tensor(clabels[nsplit:])\n",
    "\n",
    "it_labels_train = it_labels[:nsplit]\n",
    "it_labels_test = it_labels[nsplit:]\n",
    "\n",
    "print(cdata.shape, clabels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'Adam'\n",
    "lr = 1e-2\n",
    "epochs = 20\n",
    "CUDA = True\n",
    "batch_size=500\n",
    "batch_size2=500\n",
    "shuffle = False # enforce to False\n",
    "# prepare dataloader\n",
    "train_load=torch.utils.data.DataLoader(dataset=cdata_train, batch_size=batch_size, shuffle=shuffle)\n",
    "#test_load=torch.utils.data.DataLoader(dataset=cdata_test, batch_size=batch_size2, shuffle=shuffle)\n",
    "# load model \n",
    "model=ensemble_regressor_cnn()\n",
    "if CUDA:\n",
    "    model=model.cuda()\n",
    "# define a loss function\n",
    "loss_function = torch.nn.MSELoss()\n",
    "# select optimizer\n",
    "if optimizer == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "elif optimizer == 'SGD':\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=lr)\n",
    "else:\n",
    "    optimizer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test function\n",
    "def test_fn(dataloader):\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            # get labels\n",
    "            labels = torch.Tensor(clabels_test[i*batch_size2:(i+1)*batch_size2])\n",
    "            if CUDA:\n",
    "                batch =Variable(batch.cuda())\n",
    "                labels =Variable(labels.cuda())\n",
    "            else:\n",
    "                batch =Variable(batch)\n",
    "                labels =Variable(labels)\n",
    "\n",
    "            pred = model(batch)\n",
    "            test_loss += loss_function(pred, labels).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing loss\n",
    "loss_arr = np.zeros([epochs, 2])\n",
    "# training\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    # train\n",
    "    for i, batch in enumerate(train_load):\n",
    "        # get labels\n",
    "        labels = torch.Tensor(clabels_train[i*batch_size:(i+1)*batch_size])\n",
    "\n",
    "        if CUDA:\n",
    "            batch =Variable(batch.cuda())\n",
    "            labels =Variable(labels.cuda())\n",
    "        else:\n",
    "            batch =Variable(batch)\n",
    "            labels =Variable(labels)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(batch)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            loss, current = loss.item(), i * batch.shape[0]\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{nsamples:>5d}]\")\n",
    "\n",
    "            # loss on test dataset\n",
    "            # test_loss = test_fn(test_load)\n",
    "\n",
    "    # test\n",
    "    loss_arr[epoch,0] = loss\n",
    "    #loss_arr[epoch,1] = test_loss\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, dirpath_data2+model_fnm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELEP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
